{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnhtm187/Minh-T-m-31241027094/blob/main/CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/car.jpg'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QupTRBcseN1k",
        "outputId": "75422f19-9549-480d-b504-be92bb1cdff4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 41ms/step - accuracy: 0.2176 - loss: 2.1693 - val_accuracy: 0.3355 - val_loss: 1.8442\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.2976 - loss: 1.9093 - val_accuracy: 0.3754 - val_loss: 1.7681\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.3207 - loss: 1.8598 - val_accuracy: 0.3576 - val_loss: 1.8057\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3211 - loss: 1.8394 - val_accuracy: 0.3854 - val_loss: 1.7273\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.3410 - loss: 1.8058 - val_accuracy: 0.3958 - val_loss: 1.6998\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3487 - loss: 1.7735 - val_accuracy: 0.3987 - val_loss: 1.7090\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.3599 - loss: 1.7727 - val_accuracy: 0.4080 - val_loss: 1.6978\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.3647 - loss: 1.7487 - val_accuracy: 0.4044 - val_loss: 1.7199\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.3655 - loss: 1.7406 - val_accuracy: 0.4205 - val_loss: 1.6722\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.3722 - loss: 1.7260 - val_accuracy: 0.4042 - val_loss: 1.6800\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.3746 - loss: 1.7261 - val_accuracy: 0.4075 - val_loss: 1.6869\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.3839 - loss: 1.7003 - val_accuracy: 0.4223 - val_loss: 1.6567\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.3776 - loss: 1.7079 - val_accuracy: 0.4285 - val_loss: 1.6315\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 45ms/step - accuracy: 0.3896 - loss: 1.6970 - val_accuracy: 0.4198 - val_loss: 1.6406\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.3867 - loss: 1.6944 - val_accuracy: 0.4211 - val_loss: 1.6339\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.3942 - loss: 1.6772 - val_accuracy: 0.4285 - val_loss: 1.6426\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3935 - loss: 1.6783 - val_accuracy: 0.4315 - val_loss: 1.6237\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.3939 - loss: 1.6734 - val_accuracy: 0.4418 - val_loss: 1.6172\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.3992 - loss: 1.6641 - val_accuracy: 0.4451 - val_loss: 1.6119\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 42ms/step - accuracy: 0.4016 - loss: 1.6530 - val_accuracy: 0.4406 - val_loss: 1.6019\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.3972 - loss: 1.6508 - val_accuracy: 0.4369 - val_loss: 1.6141\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.4057 - loss: 1.6466 - val_accuracy: 0.4519 - val_loss: 1.5887\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.4103 - loss: 1.6357 - val_accuracy: 0.4468 - val_loss: 1.5897\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4153 - loss: 1.6247 - val_accuracy: 0.4475 - val_loss: 1.5975\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4055 - loss: 1.6417 - val_accuracy: 0.4480 - val_loss: 1.5844\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4076 - loss: 1.6330 - val_accuracy: 0.4516 - val_loss: 1.5776\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.4133 - loss: 1.6200 - val_accuracy: 0.4488 - val_loss: 1.5868\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.4084 - loss: 1.6331 - val_accuracy: 0.4500 - val_loss: 1.5786\n",
            "Epoch 29/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.4120 - loss: 1.6306 - val_accuracy: 0.4376 - val_loss: 1.5773\n",
            "Epoch 30/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4146 - loss: 1.6196 - val_accuracy: 0.4375 - val_loss: 1.6153\n",
            "Epoch 31/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.4148 - loss: 1.6258 - val_accuracy: 0.4419 - val_loss: 1.6005\n",
            "Epoch 32/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4112 - loss: 1.6199 - val_accuracy: 0.4431 - val_loss: 1.5868\n",
            "Epoch 33/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4171 - loss: 1.6105 - val_accuracy: 0.4507 - val_loss: 1.5913\n",
            "Epoch 34/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4184 - loss: 1.6083 - val_accuracy: 0.4477 - val_loss: 1.5763\n",
            "Epoch 35/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.4225 - loss: 1.6019 - val_accuracy: 0.4552 - val_loss: 1.5706\n",
            "Epoch 36/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.4170 - loss: 1.6098 - val_accuracy: 0.4418 - val_loss: 1.5888\n",
            "Epoch 37/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4215 - loss: 1.6025 - val_accuracy: 0.4542 - val_loss: 1.5652\n",
            "Epoch 38/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4211 - loss: 1.6052 - val_accuracy: 0.4636 - val_loss: 1.5719\n",
            "Epoch 39/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.4184 - loss: 1.6005 - val_accuracy: 0.4579 - val_loss: 1.5669\n",
            "Epoch 40/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4285 - loss: 1.5904 - val_accuracy: 0.4673 - val_loss: 1.5368\n",
            "Epoch 41/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4285 - loss: 1.5910 - val_accuracy: 0.4474 - val_loss: 1.6021\n",
            "Epoch 42/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.4204 - loss: 1.5979 - val_accuracy: 0.4547 - val_loss: 1.5494\n",
            "Epoch 43/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4285 - loss: 1.5840 - val_accuracy: 0.4454 - val_loss: 1.5864\n",
            "Epoch 44/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4261 - loss: 1.5888 - val_accuracy: 0.4482 - val_loss: 1.5635\n",
            "Epoch 45/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4210 - loss: 1.5944 - val_accuracy: 0.4518 - val_loss: 1.5567\n",
            "Epoch 46/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 45ms/step - accuracy: 0.4287 - loss: 1.5804 - val_accuracy: 0.4556 - val_loss: 1.5546\n",
            "Epoch 47/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - accuracy: 0.4298 - loss: 1.5748 - val_accuracy: 0.4529 - val_loss: 1.5567\n",
            "Epoch 48/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4336 - loss: 1.5642 - val_accuracy: 0.4586 - val_loss: 1.5641\n",
            "Epoch 49/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4324 - loss: 1.5781 - val_accuracy: 0.4625 - val_loss: 1.5414\n",
            "Epoch 50/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4301 - loss: 1.5770 - val_accuracy: 0.4558 - val_loss: 1.5459\n",
            "Epoch 51/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4310 - loss: 1.5735 - val_accuracy: 0.4610 - val_loss: 1.5429\n",
            "Epoch 52/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4334 - loss: 1.5654 - val_accuracy: 0.4642 - val_loss: 1.5377\n",
            "Epoch 53/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4291 - loss: 1.5924 - val_accuracy: 0.4525 - val_loss: 1.5551\n",
            "Epoch 54/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4321 - loss: 1.5714 - val_accuracy: 0.4598 - val_loss: 1.5442\n",
            "Epoch 55/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4360 - loss: 1.5627 - val_accuracy: 0.4613 - val_loss: 1.5397\n",
            "Epoch 56/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4372 - loss: 1.5575 - val_accuracy: 0.4538 - val_loss: 1.5540\n",
            "Epoch 57/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4336 - loss: 1.5594 - val_accuracy: 0.4555 - val_loss: 1.5398\n",
            "Epoch 58/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4321 - loss: 1.5642 - val_accuracy: 0.4567 - val_loss: 1.5497\n",
            "Epoch 59/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4364 - loss: 1.5604 - val_accuracy: 0.4695 - val_loss: 1.5194\n",
            "Epoch 60/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4387 - loss: 1.5529 - val_accuracy: 0.4582 - val_loss: 1.5413\n",
            "Epoch 61/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4381 - loss: 1.5590 - val_accuracy: 0.4573 - val_loss: 1.5372\n",
            "Epoch 62/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4347 - loss: 1.5593 - val_accuracy: 0.4550 - val_loss: 1.5582\n",
            "Epoch 63/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4427 - loss: 1.5499 - val_accuracy: 0.4653 - val_loss: 1.5338\n",
            "Epoch 64/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.4398 - loss: 1.5507 - val_accuracy: 0.4610 - val_loss: 1.5499\n",
            "Epoch 65/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.4398 - loss: 1.5580 - val_accuracy: 0.4578 - val_loss: 1.5345\n",
            "Epoch 66/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4405 - loss: 1.5551 - val_accuracy: 0.4582 - val_loss: 1.5414\n",
            "Epoch 67/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4409 - loss: 1.5512 - val_accuracy: 0.4631 - val_loss: 1.5296\n",
            "Epoch 68/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.4418 - loss: 1.5395 - val_accuracy: 0.4585 - val_loss: 1.5456\n",
            "Epoch 69/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4428 - loss: 1.5423 - val_accuracy: 0.4444 - val_loss: 1.5667\n",
            "Epoch 70/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4362 - loss: 1.5436 - val_accuracy: 0.4639 - val_loss: 1.5333\n",
            "Epoch 71/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.4422 - loss: 1.5554 - val_accuracy: 0.4570 - val_loss: 1.5455\n",
            "Epoch 72/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.4467 - loss: 1.5363 - val_accuracy: 0.4607 - val_loss: 1.5317\n",
            "Epoch 73/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4407 - loss: 1.5459 - val_accuracy: 0.4667 - val_loss: 1.5225\n",
            "Epoch 74/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4409 - loss: 1.5509 - val_accuracy: 0.4602 - val_loss: 1.5297\n",
            "Epoch 75/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4417 - loss: 1.5500 - val_accuracy: 0.4651 - val_loss: 1.5204\n",
            "Epoch 76/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4376 - loss: 1.5505 - val_accuracy: 0.4529 - val_loss: 1.5616\n",
            "Epoch 77/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4427 - loss: 1.5355 - val_accuracy: 0.4679 - val_loss: 1.5205\n",
            "Epoch 78/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4438 - loss: 1.5488 - val_accuracy: 0.4667 - val_loss: 1.5327\n",
            "Epoch 79/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4449 - loss: 1.5390 - val_accuracy: 0.4715 - val_loss: 1.5053\n",
            "Epoch 80/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4407 - loss: 1.5453 - val_accuracy: 0.4589 - val_loss: 1.5422\n",
            "Epoch 81/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.4375 - loss: 1.5452 - val_accuracy: 0.4751 - val_loss: 1.5146\n",
            "Epoch 82/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4418 - loss: 1.5359 - val_accuracy: 0.4614 - val_loss: 1.5332\n",
            "Epoch 83/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4442 - loss: 1.5381 - val_accuracy: 0.4684 - val_loss: 1.5201\n",
            "Epoch 84/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4453 - loss: 1.5243 - val_accuracy: 0.4689 - val_loss: 1.5164\n",
            "Epoch 85/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4483 - loss: 1.5305 - val_accuracy: 0.4691 - val_loss: 1.5232\n",
            "Epoch 86/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.4501 - loss: 1.5336 - val_accuracy: 0.4586 - val_loss: 1.5390\n",
            "Epoch 87/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.4467 - loss: 1.5262 - val_accuracy: 0.4666 - val_loss: 1.5288\n",
            "Epoch 88/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4463 - loss: 1.5279 - val_accuracy: 0.4712 - val_loss: 1.5171\n",
            "Epoch 89/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4502 - loss: 1.5252 - val_accuracy: 0.4663 - val_loss: 1.5199\n",
            "Epoch 90/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.4440 - loss: 1.5299 - val_accuracy: 0.4457 - val_loss: 1.5422\n",
            "Epoch 91/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.4472 - loss: 1.5241 - val_accuracy: 0.4676 - val_loss: 1.5140\n",
            "Epoch 92/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.4471 - loss: 1.5323 - val_accuracy: 0.4682 - val_loss: 1.5107\n",
            "Epoch 93/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4506 - loss: 1.5146 - val_accuracy: 0.4786 - val_loss: 1.5138\n",
            "Epoch 94/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.4504 - loss: 1.5285 - val_accuracy: 0.4622 - val_loss: 1.5191\n",
            "Epoch 95/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4513 - loss: 1.5235 - val_accuracy: 0.4498 - val_loss: 1.5417\n",
            "Epoch 96/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4480 - loss: 1.5229 - val_accuracy: 0.4537 - val_loss: 1.5328\n",
            "Epoch 97/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4526 - loss: 1.5162 - val_accuracy: 0.4674 - val_loss: 1.5273\n",
            "Epoch 98/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4468 - loss: 1.5286 - val_accuracy: 0.4491 - val_loss: 1.5503\n",
            "Epoch 99/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4496 - loss: 1.5171 - val_accuracy: 0.4598 - val_loss: 1.5256\n",
            "Epoch 100/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4497 - loss: 1.5110 - val_accuracy: 0.4732 - val_loss: 1.5164\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4772 - loss: 1.5110\n",
            " Độ chính xác trên tập test: 0.4731999933719635\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            " Ảnh được dự đoán là: automobile\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VInAIiMIkfFE",
        "outputId": "8a718b24-0d2e-420e-af4e-d077d2d7a88e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 89ms/step - accuracy: 0.1711 - loss: 2.2512 - val_accuracy: 0.3039 - val_loss: 1.9099\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.2638 - loss: 1.9732 - val_accuracy: 0.3351 - val_loss: 1.8715\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 83ms/step - accuracy: 0.2820 - loss: 1.9263 - val_accuracy: 0.3227 - val_loss: 1.9060\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 85ms/step - accuracy: 0.2827 - loss: 1.9093 - val_accuracy: 0.3533 - val_loss: 1.8526\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - accuracy: 0.3005 - loss: 1.8845 - val_accuracy: 0.3342 - val_loss: 1.8679\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 84ms/step - accuracy: 0.3141 - loss: 1.8607 - val_accuracy: 0.3549 - val_loss: 1.8467\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 88ms/step - accuracy: 0.3189 - loss: 1.8462 - val_accuracy: 0.3618 - val_loss: 1.8106\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - accuracy: 0.3173 - loss: 1.8354 - val_accuracy: 0.3450 - val_loss: 1.8510\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.3259 - loss: 1.8224 - val_accuracy: 0.3656 - val_loss: 1.7931\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - accuracy: 0.3346 - loss: 1.8210 - val_accuracy: 0.3717 - val_loss: 1.8101\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - accuracy: 0.3417 - loss: 1.8045 - val_accuracy: 0.3874 - val_loss: 1.7562\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.3363 - loss: 1.8076 - val_accuracy: 0.3907 - val_loss: 1.7717\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.3501 - loss: 1.7824 - val_accuracy: 0.3908 - val_loss: 1.7698\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.3478 - loss: 1.7806 - val_accuracy: 0.4010 - val_loss: 1.7343\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - accuracy: 0.3499 - loss: 1.7798 - val_accuracy: 0.3919 - val_loss: 1.7325\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.3578 - loss: 1.7618 - val_accuracy: 0.3948 - val_loss: 1.7352\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - accuracy: 0.3578 - loss: 1.7626 - val_accuracy: 0.4075 - val_loss: 1.7249\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.3542 - loss: 1.7582 - val_accuracy: 0.4047 - val_loss: 1.7309\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - accuracy: 0.3609 - loss: 1.7554 - val_accuracy: 0.3938 - val_loss: 1.7379\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 88ms/step - accuracy: 0.3619 - loss: 1.7578 - val_accuracy: 0.4124 - val_loss: 1.7220\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - accuracy: 0.3665 - loss: 1.7480 - val_accuracy: 0.4178 - val_loss: 1.7011\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.3683 - loss: 1.7442 - val_accuracy: 0.4172 - val_loss: 1.6961\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.3696 - loss: 1.7330 - val_accuracy: 0.4068 - val_loss: 1.7064\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 88ms/step - accuracy: 0.3726 - loss: 1.7337 - val_accuracy: 0.4102 - val_loss: 1.7143\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - accuracy: 0.3758 - loss: 1.7196 - val_accuracy: 0.4069 - val_loss: 1.6972\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 94ms/step - accuracy: 0.3749 - loss: 1.7250 - val_accuracy: 0.4130 - val_loss: 1.6735\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 87ms/step - accuracy: 0.3823 - loss: 1.7113 - val_accuracy: 0.4259 - val_loss: 1.7045\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - accuracy: 0.3775 - loss: 1.7107 - val_accuracy: 0.4215 - val_loss: 1.6803\n",
            "Epoch 29/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 92ms/step - accuracy: 0.3792 - loss: 1.7091 - val_accuracy: 0.4177 - val_loss: 1.6934\n",
            "Epoch 30/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 86ms/step - accuracy: 0.3823 - loss: 1.7067 - val_accuracy: 0.4200 - val_loss: 1.6820\n",
            "Epoch 31/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.3805 - loss: 1.7067 - val_accuracy: 0.4222 - val_loss: 1.6752\n",
            "Epoch 32/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 89ms/step - accuracy: 0.3855 - loss: 1.7056 - val_accuracy: 0.4012 - val_loss: 1.7053\n",
            "Epoch 33/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - accuracy: 0.3793 - loss: 1.7036 - val_accuracy: 0.4171 - val_loss: 1.6702\n",
            "Epoch 34/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.3877 - loss: 1.6862 - val_accuracy: 0.4152 - val_loss: 1.6764\n",
            "Epoch 35/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 87ms/step - accuracy: 0.3817 - loss: 1.6986 - val_accuracy: 0.4258 - val_loss: 1.6743\n",
            "Epoch 36/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.3880 - loss: 1.6943 - val_accuracy: 0.4207 - val_loss: 1.6828\n",
            "Epoch 37/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 85ms/step - accuracy: 0.3927 - loss: 1.6845 - val_accuracy: 0.4222 - val_loss: 1.6776\n",
            "Epoch 38/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - accuracy: 0.3932 - loss: 1.6796 - val_accuracy: 0.4122 - val_loss: 1.6878\n",
            "Epoch 39/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - accuracy: 0.3919 - loss: 1.6824 - val_accuracy: 0.4292 - val_loss: 1.6523\n",
            "Epoch 40/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 90ms/step - accuracy: 0.3889 - loss: 1.6856 - val_accuracy: 0.4297 - val_loss: 1.6554\n",
            "Epoch 41/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - accuracy: 0.3887 - loss: 1.6784 - val_accuracy: 0.4248 - val_loss: 1.6705\n",
            "Epoch 42/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.3948 - loss: 1.6761 - val_accuracy: 0.4325 - val_loss: 1.6458\n",
            "Epoch 43/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 87ms/step - accuracy: 0.3959 - loss: 1.6757 - val_accuracy: 0.4305 - val_loss: 1.6502\n",
            "Epoch 44/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.3975 - loss: 1.6753 - val_accuracy: 0.4362 - val_loss: 1.6408\n",
            "Epoch 45/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 85ms/step - accuracy: 0.4025 - loss: 1.6723 - val_accuracy: 0.4334 - val_loss: 1.6226\n",
            "Epoch 46/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4015 - loss: 1.6680 - val_accuracy: 0.4330 - val_loss: 1.6476\n",
            "Epoch 47/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 82ms/step - accuracy: 0.3976 - loss: 1.6700 - val_accuracy: 0.4355 - val_loss: 1.6462\n",
            "Epoch 48/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 87ms/step - accuracy: 0.4035 - loss: 1.6565 - val_accuracy: 0.4273 - val_loss: 1.6492\n",
            "Epoch 49/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 86ms/step - accuracy: 0.3976 - loss: 1.6697 - val_accuracy: 0.4268 - val_loss: 1.6571\n",
            "Epoch 50/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.4025 - loss: 1.6618 - val_accuracy: 0.4309 - val_loss: 1.6517\n",
            "Epoch 51/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 88ms/step - accuracy: 0.3975 - loss: 1.6653 - val_accuracy: 0.4255 - val_loss: 1.6751\n",
            "Epoch 52/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4074 - loss: 1.6523 - val_accuracy: 0.4317 - val_loss: 1.6570\n",
            "Epoch 53/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4049 - loss: 1.6498 - val_accuracy: 0.4359 - val_loss: 1.6341\n",
            "Epoch 54/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4010 - loss: 1.6601 - val_accuracy: 0.4396 - val_loss: 1.6523\n",
            "Epoch 55/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4055 - loss: 1.6427 - val_accuracy: 0.4277 - val_loss: 1.6770\n",
            "Epoch 56/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - accuracy: 0.4088 - loss: 1.6425 - val_accuracy: 0.4258 - val_loss: 1.6642\n",
            "Epoch 57/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - accuracy: 0.4083 - loss: 1.6485 - val_accuracy: 0.4246 - val_loss: 1.6693\n",
            "Epoch 58/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4013 - loss: 1.6496 - val_accuracy: 0.4366 - val_loss: 1.6479\n",
            "Epoch 59/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4060 - loss: 1.6446 - val_accuracy: 0.4317 - val_loss: 1.6569\n",
            "Epoch 60/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 84ms/step - accuracy: 0.4074 - loss: 1.6354 - val_accuracy: 0.4374 - val_loss: 1.6589\n",
            "Epoch 61/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - accuracy: 0.4061 - loss: 1.6377 - val_accuracy: 0.4409 - val_loss: 1.6140\n",
            "Epoch 62/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - accuracy: 0.4018 - loss: 1.6474 - val_accuracy: 0.4223 - val_loss: 1.6606\n",
            "Epoch 63/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4080 - loss: 1.6327 - val_accuracy: 0.4207 - val_loss: 1.6451\n",
            "Epoch 64/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.4095 - loss: 1.6430 - val_accuracy: 0.4362 - val_loss: 1.6359\n",
            "Epoch 65/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 85ms/step - accuracy: 0.4078 - loss: 1.6355 - val_accuracy: 0.4357 - val_loss: 1.6234\n",
            "Epoch 66/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4172 - loss: 1.6294 - val_accuracy: 0.4426 - val_loss: 1.6081\n",
            "Epoch 67/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4114 - loss: 1.6273 - val_accuracy: 0.4366 - val_loss: 1.6216\n",
            "Epoch 68/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4092 - loss: 1.6286 - val_accuracy: 0.4337 - val_loss: 1.6307\n",
            "Epoch 69/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - accuracy: 0.4107 - loss: 1.6258 - val_accuracy: 0.4432 - val_loss: 1.6169\n",
            "Epoch 70/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - accuracy: 0.4133 - loss: 1.6238 - val_accuracy: 0.4383 - val_loss: 1.6368\n",
            "Epoch 71/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4151 - loss: 1.6218 - val_accuracy: 0.4392 - val_loss: 1.6316\n",
            "Epoch 72/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4139 - loss: 1.6243 - val_accuracy: 0.4327 - val_loss: 1.6268\n",
            "Epoch 73/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 87ms/step - accuracy: 0.4118 - loss: 1.6262 - val_accuracy: 0.4476 - val_loss: 1.6104\n",
            "Epoch 74/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4126 - loss: 1.6252 - val_accuracy: 0.4246 - val_loss: 1.6624\n",
            "Epoch 75/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4129 - loss: 1.6250 - val_accuracy: 0.4369 - val_loss: 1.6208\n",
            "Epoch 76/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - accuracy: 0.4190 - loss: 1.6143 - val_accuracy: 0.4457 - val_loss: 1.6138\n",
            "Epoch 77/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - accuracy: 0.4185 - loss: 1.6180 - val_accuracy: 0.4272 - val_loss: 1.6448\n",
            "Epoch 78/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4207 - loss: 1.6082 - val_accuracy: 0.4361 - val_loss: 1.6192\n",
            "Epoch 79/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.4121 - loss: 1.6280 - val_accuracy: 0.4418 - val_loss: 1.6174\n",
            "Epoch 80/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - accuracy: 0.4161 - loss: 1.6147 - val_accuracy: 0.4338 - val_loss: 1.6342\n",
            "Epoch 81/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.4176 - loss: 1.6054 - val_accuracy: 0.4410 - val_loss: 1.6110\n",
            "Epoch 82/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.4162 - loss: 1.6155 - val_accuracy: 0.4379 - val_loss: 1.6077\n",
            "Epoch 83/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 84ms/step - accuracy: 0.4187 - loss: 1.6061 - val_accuracy: 0.4176 - val_loss: 1.6749\n",
            "Epoch 84/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - accuracy: 0.4147 - loss: 1.6178 - val_accuracy: 0.4358 - val_loss: 1.6334\n",
            "Epoch 85/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4243 - loss: 1.5954 - val_accuracy: 0.4333 - val_loss: 1.6153\n",
            "Epoch 86/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 93ms/step - accuracy: 0.4168 - loss: 1.6106 - val_accuracy: 0.4409 - val_loss: 1.6122\n",
            "Epoch 87/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 87ms/step - accuracy: 0.4250 - loss: 1.6012 - val_accuracy: 0.4336 - val_loss: 1.6348\n",
            "Epoch 88/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - accuracy: 0.4172 - loss: 1.6156 - val_accuracy: 0.4401 - val_loss: 1.6171\n",
            "Epoch 89/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 90ms/step - accuracy: 0.4219 - loss: 1.6063 - val_accuracy: 0.4363 - val_loss: 1.6228\n",
            "Epoch 90/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 87ms/step - accuracy: 0.4232 - loss: 1.5977 - val_accuracy: 0.4459 - val_loss: 1.5987\n",
            "Epoch 91/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - accuracy: 0.4176 - loss: 1.6098 - val_accuracy: 0.4442 - val_loss: 1.5939\n",
            "Epoch 92/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - accuracy: 0.4271 - loss: 1.5810 - val_accuracy: 0.4397 - val_loss: 1.6369\n",
            "Epoch 93/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4284 - loss: 1.6008 - val_accuracy: 0.4362 - val_loss: 1.6088\n",
            "Epoch 94/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.4269 - loss: 1.5916 - val_accuracy: 0.4436 - val_loss: 1.6043\n",
            "Epoch 95/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 94ms/step - accuracy: 0.4250 - loss: 1.5921 - val_accuracy: 0.4392 - val_loss: 1.6137\n",
            "Epoch 96/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 89ms/step - accuracy: 0.4251 - loss: 1.5937 - val_accuracy: 0.4390 - val_loss: 1.6434\n",
            "Epoch 97/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 91ms/step - accuracy: 0.4235 - loss: 1.6065 - val_accuracy: 0.4374 - val_loss: 1.6182\n",
            "Epoch 98/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 90ms/step - accuracy: 0.4246 - loss: 1.5954 - val_accuracy: 0.4406 - val_loss: 1.6165\n",
            "Epoch 99/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 91ms/step - accuracy: 0.4258 - loss: 1.5881 - val_accuracy: 0.4501 - val_loss: 1.5954\n",
            "Epoch 100/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - accuracy: 0.4254 - loss: 1.5956 - val_accuracy: 0.4530 - val_loss: 1.5936\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4519 - loss: 1.5907\n",
            " Độ chính xác trên tập test: 0.453000009059906\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            " Ảnh được dự đoán là: cat\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/bird.jpg'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/cat.webp'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5lmaP75sp0oz",
        "outputId": "4dff8112-0c5a-4822-ae76-ad6c980221f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.2109 - loss: 2.2118 - val_accuracy: 0.3279 - val_loss: 1.8578\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.3021 - loss: 1.9250 - val_accuracy: 0.3619 - val_loss: 1.7758\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.3255 - loss: 1.8483 - val_accuracy: 0.3951 - val_loss: 1.7268\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 42ms/step - accuracy: 0.3455 - loss: 1.8055 - val_accuracy: 0.3889 - val_loss: 1.7260\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3501 - loss: 1.7833 - val_accuracy: 0.4093 - val_loss: 1.6899\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.3580 - loss: 1.7683 - val_accuracy: 0.4188 - val_loss: 1.6640\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.3705 - loss: 1.7417 - val_accuracy: 0.4149 - val_loss: 1.6663\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.3673 - loss: 1.7426 - val_accuracy: 0.4306 - val_loss: 1.6541\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.3782 - loss: 1.7179 - val_accuracy: 0.4230 - val_loss: 1.6579\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.3763 - loss: 1.7155 - val_accuracy: 0.4253 - val_loss: 1.6317\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.3892 - loss: 1.6919 - val_accuracy: 0.4229 - val_loss: 1.6548\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.3870 - loss: 1.6911 - val_accuracy: 0.4179 - val_loss: 1.6373\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3906 - loss: 1.6862 - val_accuracy: 0.4321 - val_loss: 1.6259\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.3895 - loss: 1.6870 - val_accuracy: 0.4407 - val_loss: 1.6157\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.3951 - loss: 1.6811 - val_accuracy: 0.4423 - val_loss: 1.6185\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.3946 - loss: 1.6768 - val_accuracy: 0.4268 - val_loss: 1.6393\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.3943 - loss: 1.6748 - val_accuracy: 0.4442 - val_loss: 1.6165\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4001 - loss: 1.6609 - val_accuracy: 0.4258 - val_loss: 1.6189\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3999 - loss: 1.6666 - val_accuracy: 0.4279 - val_loss: 1.6114\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - accuracy: 0.4006 - loss: 1.6585 - val_accuracy: 0.4463 - val_loss: 1.6079\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4068 - loss: 1.6455 - val_accuracy: 0.4454 - val_loss: 1.5923\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4073 - loss: 1.6436 - val_accuracy: 0.4416 - val_loss: 1.5959\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4065 - loss: 1.6469 - val_accuracy: 0.4472 - val_loss: 1.6024\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4112 - loss: 1.6384 - val_accuracy: 0.4537 - val_loss: 1.5836\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4117 - loss: 1.6242 - val_accuracy: 0.4398 - val_loss: 1.5867\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4105 - loss: 1.6296 - val_accuracy: 0.4302 - val_loss: 1.6128\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4093 - loss: 1.6263 - val_accuracy: 0.4388 - val_loss: 1.5994\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4130 - loss: 1.6270 - val_accuracy: 0.4438 - val_loss: 1.5824\n",
            "Epoch 29/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4163 - loss: 1.6224 - val_accuracy: 0.4346 - val_loss: 1.5880\n",
            "Epoch 30/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4144 - loss: 1.6167 - val_accuracy: 0.4512 - val_loss: 1.5651\n",
            "Epoch 31/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4165 - loss: 1.6095 - val_accuracy: 0.4612 - val_loss: 1.5726\n",
            "Epoch 32/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4170 - loss: 1.6058 - val_accuracy: 0.4615 - val_loss: 1.5644\n",
            "Epoch 33/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4219 - loss: 1.6099 - val_accuracy: 0.4504 - val_loss: 1.5778\n",
            "Epoch 34/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4196 - loss: 1.6141 - val_accuracy: 0.4492 - val_loss: 1.5673\n",
            "Epoch 35/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4244 - loss: 1.5935 - val_accuracy: 0.4521 - val_loss: 1.5748\n",
            "Epoch 36/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4186 - loss: 1.6012 - val_accuracy: 0.4467 - val_loss: 1.5833\n",
            "Epoch 37/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.4275 - loss: 1.5981 - val_accuracy: 0.4361 - val_loss: 1.5943\n",
            "Epoch 38/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4257 - loss: 1.5986 - val_accuracy: 0.4504 - val_loss: 1.5595\n",
            "Epoch 39/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4238 - loss: 1.6043 - val_accuracy: 0.4623 - val_loss: 1.5369\n",
            "Epoch 40/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.4237 - loss: 1.5945 - val_accuracy: 0.4502 - val_loss: 1.5547\n",
            "Epoch 41/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4237 - loss: 1.5915 - val_accuracy: 0.4452 - val_loss: 1.5639\n",
            "Epoch 42/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4227 - loss: 1.5920 - val_accuracy: 0.4683 - val_loss: 1.5407\n",
            "Epoch 43/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4266 - loss: 1.5887 - val_accuracy: 0.4618 - val_loss: 1.5681\n",
            "Epoch 44/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4349 - loss: 1.5665 - val_accuracy: 0.4574 - val_loss: 1.5661\n",
            "Epoch 45/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4336 - loss: 1.5792 - val_accuracy: 0.4591 - val_loss: 1.5436\n",
            "Epoch 46/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4265 - loss: 1.5862 - val_accuracy: 0.4506 - val_loss: 1.5621\n",
            "Epoch 47/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4309 - loss: 1.5837 - val_accuracy: 0.4615 - val_loss: 1.5488\n",
            "Epoch 48/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - accuracy: 0.4306 - loss: 1.5801 - val_accuracy: 0.4679 - val_loss: 1.5329\n",
            "Epoch 49/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4313 - loss: 1.5753 - val_accuracy: 0.4543 - val_loss: 1.5663\n",
            "Epoch 50/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4324 - loss: 1.5762 - val_accuracy: 0.4537 - val_loss: 1.5738\n",
            "Epoch 51/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4269 - loss: 1.5869 - val_accuracy: 0.4526 - val_loss: 1.5460\n",
            "Epoch 52/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4289 - loss: 1.5824 - val_accuracy: 0.4646 - val_loss: 1.5397\n",
            "Epoch 53/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4313 - loss: 1.5769 - val_accuracy: 0.4603 - val_loss: 1.5510\n",
            "Epoch 54/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.4316 - loss: 1.5766 - val_accuracy: 0.4501 - val_loss: 1.5583\n",
            "Epoch 55/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4304 - loss: 1.5808 - val_accuracy: 0.4622 - val_loss: 1.5512\n",
            "Epoch 56/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4356 - loss: 1.5657 - val_accuracy: 0.4626 - val_loss: 1.5488\n",
            "Epoch 57/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4359 - loss: 1.5682 - val_accuracy: 0.4630 - val_loss: 1.5372\n",
            "Epoch 58/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4362 - loss: 1.5646 - val_accuracy: 0.4618 - val_loss: 1.5347\n",
            "Epoch 59/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4380 - loss: 1.5649 - val_accuracy: 0.4619 - val_loss: 1.5446\n",
            "Epoch 60/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4379 - loss: 1.5674 - val_accuracy: 0.4701 - val_loss: 1.5439\n",
            "Epoch 61/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4383 - loss: 1.5562 - val_accuracy: 0.4676 - val_loss: 1.5457\n",
            "Epoch 62/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4300 - loss: 1.5716 - val_accuracy: 0.4688 - val_loss: 1.5374\n",
            "Epoch 63/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4391 - loss: 1.5632 - val_accuracy: 0.4623 - val_loss: 1.5367\n",
            "Epoch 64/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4358 - loss: 1.5629 - val_accuracy: 0.4514 - val_loss: 1.5655\n",
            "Epoch 65/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4381 - loss: 1.5562 - val_accuracy: 0.4681 - val_loss: 1.5377\n",
            "Epoch 66/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4436 - loss: 1.5424 - val_accuracy: 0.4648 - val_loss: 1.5294\n",
            "Epoch 67/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4443 - loss: 1.5449 - val_accuracy: 0.4583 - val_loss: 1.5317\n",
            "Epoch 68/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4346 - loss: 1.5585 - val_accuracy: 0.4598 - val_loss: 1.5433\n",
            "Epoch 69/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4403 - loss: 1.5423 - val_accuracy: 0.4608 - val_loss: 1.5499\n",
            "Epoch 70/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4415 - loss: 1.5551 - val_accuracy: 0.4684 - val_loss: 1.5436\n",
            "Epoch 71/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4404 - loss: 1.5458 - val_accuracy: 0.4589 - val_loss: 1.5491\n",
            "Epoch 72/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4402 - loss: 1.5517 - val_accuracy: 0.4662 - val_loss: 1.5418\n",
            "Epoch 73/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4442 - loss: 1.5420 - val_accuracy: 0.4506 - val_loss: 1.5448\n",
            "Epoch 74/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - accuracy: 0.4405 - loss: 1.5507 - val_accuracy: 0.4722 - val_loss: 1.5259\n",
            "Epoch 75/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4490 - loss: 1.5419 - val_accuracy: 0.4619 - val_loss: 1.5456\n",
            "Epoch 76/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4444 - loss: 1.5459 - val_accuracy: 0.4647 - val_loss: 1.5348\n",
            "Epoch 77/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4429 - loss: 1.5436 - val_accuracy: 0.4634 - val_loss: 1.5379\n",
            "Epoch 78/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4458 - loss: 1.5368 - val_accuracy: 0.4613 - val_loss: 1.5420\n",
            "Epoch 79/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4464 - loss: 1.5460 - val_accuracy: 0.4679 - val_loss: 1.5228\n",
            "Epoch 80/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4396 - loss: 1.5417 - val_accuracy: 0.4691 - val_loss: 1.5295\n",
            "Epoch 81/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4437 - loss: 1.5486 - val_accuracy: 0.4752 - val_loss: 1.5177\n",
            "Epoch 82/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4531 - loss: 1.5273 - val_accuracy: 0.4664 - val_loss: 1.5320\n",
            "Epoch 83/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.4529 - loss: 1.5264 - val_accuracy: 0.4688 - val_loss: 1.5443\n",
            "Epoch 84/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.4451 - loss: 1.5264 - val_accuracy: 0.4716 - val_loss: 1.5195\n",
            "Epoch 85/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4491 - loss: 1.5266 - val_accuracy: 0.4648 - val_loss: 1.5503\n",
            "Epoch 86/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.4472 - loss: 1.5356 - val_accuracy: 0.4730 - val_loss: 1.5152\n",
            "Epoch 87/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4435 - loss: 1.5357 - val_accuracy: 0.4616 - val_loss: 1.5340\n",
            "Epoch 88/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4484 - loss: 1.5322 - val_accuracy: 0.4611 - val_loss: 1.5310\n",
            "Epoch 89/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4485 - loss: 1.5294 - val_accuracy: 0.4809 - val_loss: 1.5025\n",
            "Epoch 90/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.4499 - loss: 1.5372 - val_accuracy: 0.4661 - val_loss: 1.5302\n",
            "Epoch 91/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.4461 - loss: 1.5351 - val_accuracy: 0.4683 - val_loss: 1.5222\n",
            "Epoch 92/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4497 - loss: 1.5255 - val_accuracy: 0.4707 - val_loss: 1.5297\n",
            "Epoch 93/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4519 - loss: 1.5316 - val_accuracy: 0.4596 - val_loss: 1.5264\n",
            "Epoch 94/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4442 - loss: 1.5364 - val_accuracy: 0.4765 - val_loss: 1.5111\n",
            "Epoch 95/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4551 - loss: 1.5071 - val_accuracy: 0.4653 - val_loss: 1.5408\n",
            "Epoch 96/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4506 - loss: 1.5326 - val_accuracy: 0.4689 - val_loss: 1.5276\n",
            "Epoch 97/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4495 - loss: 1.5254 - val_accuracy: 0.4700 - val_loss: 1.5235\n",
            "Epoch 98/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.4501 - loss: 1.5254 - val_accuracy: 0.4553 - val_loss: 1.5494\n",
            "Epoch 99/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4519 - loss: 1.5279 - val_accuracy: 0.4624 - val_loss: 1.5216\n",
            "Epoch 100/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4530 - loss: 1.5183 - val_accuracy: 0.4722 - val_loss: 1.5098\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4773 - loss: 1.5014\n",
            " Độ chính xác trên tập test: 0.4722000062465668\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            " Ảnh được dự đoán là: cat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/deer.jpg'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jGaraZk0-JwU",
        "outputId": "4a34e145-9db3-4823-f340-e2e75d8da94b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 43ms/step - accuracy: 0.2153 - loss: 2.1818 - val_accuracy: 0.3260 - val_loss: 1.8496\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 42ms/step - accuracy: 0.3105 - loss: 1.8901 - val_accuracy: 0.3697 - val_loss: 1.7586\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.3297 - loss: 1.8339 - val_accuracy: 0.3968 - val_loss: 1.7279\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.3408 - loss: 1.8152 - val_accuracy: 0.3931 - val_loss: 1.7132\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3556 - loss: 1.7815 - val_accuracy: 0.4073 - val_loss: 1.7010\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.3579 - loss: 1.7770 - val_accuracy: 0.4260 - val_loss: 1.6652\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.3662 - loss: 1.7516 - val_accuracy: 0.4210 - val_loss: 1.6620\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.3729 - loss: 1.7351 - val_accuracy: 0.4254 - val_loss: 1.6487\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3760 - loss: 1.7130 - val_accuracy: 0.4227 - val_loss: 1.6474\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.3900 - loss: 1.6947 - val_accuracy: 0.4221 - val_loss: 1.6574\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.3833 - loss: 1.7047 - val_accuracy: 0.4295 - val_loss: 1.6393\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3850 - loss: 1.6961 - val_accuracy: 0.4348 - val_loss: 1.6254\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.3924 - loss: 1.6834 - val_accuracy: 0.4115 - val_loss: 1.6602\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.3928 - loss: 1.6907 - val_accuracy: 0.4337 - val_loss: 1.6262\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.3934 - loss: 1.6758 - val_accuracy: 0.4314 - val_loss: 1.6278\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3971 - loss: 1.6671 - val_accuracy: 0.4485 - val_loss: 1.5927\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3949 - loss: 1.6691 - val_accuracy: 0.4388 - val_loss: 1.5898\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4038 - loss: 1.6493 - val_accuracy: 0.4417 - val_loss: 1.6231\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4042 - loss: 1.6476 - val_accuracy: 0.4395 - val_loss: 1.6057\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4056 - loss: 1.6445 - val_accuracy: 0.4481 - val_loss: 1.5876\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.3982 - loss: 1.6575 - val_accuracy: 0.4456 - val_loss: 1.5848\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4050 - loss: 1.6416 - val_accuracy: 0.4491 - val_loss: 1.5863\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 42ms/step - accuracy: 0.4086 - loss: 1.6338 - val_accuracy: 0.4358 - val_loss: 1.6010\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4117 - loss: 1.6279 - val_accuracy: 0.4518 - val_loss: 1.5866\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4151 - loss: 1.6190 - val_accuracy: 0.4406 - val_loss: 1.5923\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4170 - loss: 1.6252 - val_accuracy: 0.4478 - val_loss: 1.5828\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4192 - loss: 1.6124 - val_accuracy: 0.4621 - val_loss: 1.5775\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4141 - loss: 1.6232 - val_accuracy: 0.4418 - val_loss: 1.5896\n",
            "Epoch 29/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.4175 - loss: 1.6160 - val_accuracy: 0.4520 - val_loss: 1.5584\n",
            "Epoch 30/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4247 - loss: 1.5962 - val_accuracy: 0.4587 - val_loss: 1.5485\n",
            "Epoch 31/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4191 - loss: 1.6099 - val_accuracy: 0.4369 - val_loss: 1.5859\n",
            "Epoch 32/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4229 - loss: 1.5979 - val_accuracy: 0.4515 - val_loss: 1.5595\n",
            "Epoch 33/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4204 - loss: 1.5940 - val_accuracy: 0.4527 - val_loss: 1.5739\n",
            "Epoch 34/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4190 - loss: 1.6065 - val_accuracy: 0.4512 - val_loss: 1.5823\n",
            "Epoch 35/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4240 - loss: 1.5943 - val_accuracy: 0.4320 - val_loss: 1.5610\n",
            "Epoch 36/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4230 - loss: 1.6020 - val_accuracy: 0.4606 - val_loss: 1.5465\n",
            "Epoch 37/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4263 - loss: 1.5833 - val_accuracy: 0.4653 - val_loss: 1.5476\n",
            "Epoch 38/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4268 - loss: 1.5929 - val_accuracy: 0.4650 - val_loss: 1.5604\n",
            "Epoch 39/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4283 - loss: 1.5787 - val_accuracy: 0.4587 - val_loss: 1.5623\n",
            "Epoch 40/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4297 - loss: 1.5803 - val_accuracy: 0.4584 - val_loss: 1.5582\n",
            "Epoch 41/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4293 - loss: 1.5895 - val_accuracy: 0.4533 - val_loss: 1.5648\n",
            "Epoch 42/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4225 - loss: 1.5852 - val_accuracy: 0.4603 - val_loss: 1.5505\n",
            "Epoch 43/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4299 - loss: 1.5826 - val_accuracy: 0.4534 - val_loss: 1.5617\n",
            "Epoch 44/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.4270 - loss: 1.5876 - val_accuracy: 0.4639 - val_loss: 1.5381\n",
            "Epoch 45/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4305 - loss: 1.5736 - val_accuracy: 0.4451 - val_loss: 1.5608\n",
            "Epoch 46/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4322 - loss: 1.5729 - val_accuracy: 0.4590 - val_loss: 1.5435\n",
            "Epoch 47/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4391 - loss: 1.5662 - val_accuracy: 0.4561 - val_loss: 1.5669\n",
            "Epoch 48/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4364 - loss: 1.5687 - val_accuracy: 0.4585 - val_loss: 1.5569\n",
            "Epoch 49/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4366 - loss: 1.5631 - val_accuracy: 0.4540 - val_loss: 1.5525\n",
            "Epoch 50/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4421 - loss: 1.5666 - val_accuracy: 0.4554 - val_loss: 1.5508\n",
            "Epoch 51/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4354 - loss: 1.5668 - val_accuracy: 0.4625 - val_loss: 1.5435\n",
            "Epoch 52/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4411 - loss: 1.5535 - val_accuracy: 0.4653 - val_loss: 1.5376\n",
            "Epoch 53/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4412 - loss: 1.5507 - val_accuracy: 0.4626 - val_loss: 1.5421\n",
            "Epoch 54/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4388 - loss: 1.5607 - val_accuracy: 0.4571 - val_loss: 1.5353\n",
            "Epoch 55/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4397 - loss: 1.5551 - val_accuracy: 0.4655 - val_loss: 1.5425\n",
            "Epoch 56/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4430 - loss: 1.5515 - val_accuracy: 0.4557 - val_loss: 1.5590\n",
            "Epoch 57/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4400 - loss: 1.5548 - val_accuracy: 0.4594 - val_loss: 1.5465\n",
            "Epoch 58/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4404 - loss: 1.5533 - val_accuracy: 0.4661 - val_loss: 1.5341\n",
            "Epoch 59/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4381 - loss: 1.5599 - val_accuracy: 0.4740 - val_loss: 1.5432\n",
            "Epoch 60/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4422 - loss: 1.5552 - val_accuracy: 0.4616 - val_loss: 1.5366\n",
            "Epoch 61/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4388 - loss: 1.5580 - val_accuracy: 0.4630 - val_loss: 1.5372\n",
            "Epoch 62/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4429 - loss: 1.5479 - val_accuracy: 0.4539 - val_loss: 1.5415\n",
            "Epoch 63/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4441 - loss: 1.5521 - val_accuracy: 0.4612 - val_loss: 1.5477\n",
            "Epoch 64/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4421 - loss: 1.5515 - val_accuracy: 0.4614 - val_loss: 1.5191\n",
            "Epoch 65/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4422 - loss: 1.5522 - val_accuracy: 0.4622 - val_loss: 1.5225\n",
            "Epoch 66/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4432 - loss: 1.5403 - val_accuracy: 0.4765 - val_loss: 1.5186\n",
            "Epoch 67/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4484 - loss: 1.5404 - val_accuracy: 0.4775 - val_loss: 1.5181\n",
            "Epoch 68/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4445 - loss: 1.5446 - val_accuracy: 0.4684 - val_loss: 1.5194\n",
            "Epoch 69/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4472 - loss: 1.5428 - val_accuracy: 0.4620 - val_loss: 1.5363\n",
            "Epoch 70/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4497 - loss: 1.5366 - val_accuracy: 0.4684 - val_loss: 1.5296\n",
            "Epoch 71/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4479 - loss: 1.5381 - val_accuracy: 0.4757 - val_loss: 1.5197\n",
            "Epoch 72/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4473 - loss: 1.5382 - val_accuracy: 0.4593 - val_loss: 1.5442\n",
            "Epoch 73/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4493 - loss: 1.5368 - val_accuracy: 0.4783 - val_loss: 1.5114\n",
            "Epoch 74/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4482 - loss: 1.5232 - val_accuracy: 0.4634 - val_loss: 1.5526\n",
            "Epoch 75/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - accuracy: 0.4470 - loss: 1.5372 - val_accuracy: 0.4646 - val_loss: 1.5279\n",
            "Epoch 76/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4482 - loss: 1.5337 - val_accuracy: 0.4662 - val_loss: 1.5252\n",
            "Epoch 77/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.4513 - loss: 1.5293 - val_accuracy: 0.4699 - val_loss: 1.5258\n",
            "Epoch 78/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4505 - loss: 1.5282 - val_accuracy: 0.4728 - val_loss: 1.5141\n",
            "Epoch 79/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4501 - loss: 1.5255 - val_accuracy: 0.4530 - val_loss: 1.5705\n",
            "Epoch 80/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4500 - loss: 1.5255 - val_accuracy: 0.4576 - val_loss: 1.5329\n",
            "Epoch 81/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4503 - loss: 1.5311 - val_accuracy: 0.4720 - val_loss: 1.5279\n",
            "Epoch 82/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4502 - loss: 1.5296 - val_accuracy: 0.4821 - val_loss: 1.4975\n",
            "Epoch 83/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4515 - loss: 1.5288 - val_accuracy: 0.4594 - val_loss: 1.5439\n",
            "Epoch 84/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4523 - loss: 1.5274 - val_accuracy: 0.4822 - val_loss: 1.4975\n",
            "Epoch 85/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4563 - loss: 1.5154 - val_accuracy: 0.4665 - val_loss: 1.5208\n",
            "Epoch 86/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4508 - loss: 1.5272 - val_accuracy: 0.4674 - val_loss: 1.5204\n",
            "Epoch 87/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4490 - loss: 1.5223 - val_accuracy: 0.4697 - val_loss: 1.5190\n",
            "Epoch 88/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4485 - loss: 1.5223 - val_accuracy: 0.4698 - val_loss: 1.5060\n",
            "Epoch 89/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4496 - loss: 1.5158 - val_accuracy: 0.4808 - val_loss: 1.4994\n",
            "Epoch 90/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4529 - loss: 1.5188 - val_accuracy: 0.4718 - val_loss: 1.5121\n",
            "Epoch 91/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4547 - loss: 1.5104 - val_accuracy: 0.4620 - val_loss: 1.5311\n",
            "Epoch 92/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4601 - loss: 1.5001 - val_accuracy: 0.4624 - val_loss: 1.5496\n",
            "Epoch 93/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4546 - loss: 1.5189 - val_accuracy: 0.4711 - val_loss: 1.5200\n",
            "Epoch 94/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4544 - loss: 1.5201 - val_accuracy: 0.4643 - val_loss: 1.5310\n",
            "Epoch 95/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4549 - loss: 1.5115 - val_accuracy: 0.4625 - val_loss: 1.5071\n",
            "Epoch 96/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4554 - loss: 1.5147 - val_accuracy: 0.4589 - val_loss: 1.5330\n",
            "Epoch 97/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4498 - loss: 1.5265 - val_accuracy: 0.4728 - val_loss: 1.5161\n",
            "Epoch 98/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4580 - loss: 1.5062 - val_accuracy: 0.4649 - val_loss: 1.5193\n",
            "Epoch 99/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4562 - loss: 1.5187 - val_accuracy: 0.4682 - val_loss: 1.5276\n",
            "Epoch 100/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4569 - loss: 1.5151 - val_accuracy: 0.4516 - val_loss: 1.5426\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4553 - loss: 1.5397\n",
            " Độ chính xác trên tập test: 0.45159998536109924\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            " Ảnh được dự đoán là: horse\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/dog.jpg'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fgW2IhIN-OUC",
        "outputId": "9e03b289-b3cf-4ac8-e10e-c8e81a1de066"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.2136 - loss: 2.1613 - val_accuracy: 0.3454 - val_loss: 1.8214\n",
            "Epoch 2/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3095 - loss: 1.8864 - val_accuracy: 0.3709 - val_loss: 1.7598\n",
            "Epoch 3/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.3310 - loss: 1.8384 - val_accuracy: 0.3946 - val_loss: 1.7255\n",
            "Epoch 4/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.3450 - loss: 1.7991 - val_accuracy: 0.4039 - val_loss: 1.7003\n",
            "Epoch 5/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.3546 - loss: 1.7721 - val_accuracy: 0.4081 - val_loss: 1.6795\n",
            "Epoch 6/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.3652 - loss: 1.7404 - val_accuracy: 0.4218 - val_loss: 1.6635\n",
            "Epoch 7/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.3690 - loss: 1.7401 - val_accuracy: 0.4257 - val_loss: 1.6383\n",
            "Epoch 8/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3746 - loss: 1.7369 - val_accuracy: 0.4324 - val_loss: 1.6429\n",
            "Epoch 9/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.3804 - loss: 1.7023 - val_accuracy: 0.4354 - val_loss: 1.6519\n",
            "Epoch 10/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.3898 - loss: 1.6967 - val_accuracy: 0.4381 - val_loss: 1.6265\n",
            "Epoch 11/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.3922 - loss: 1.6898 - val_accuracy: 0.4378 - val_loss: 1.6183\n",
            "Epoch 12/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.3953 - loss: 1.6709 - val_accuracy: 0.4407 - val_loss: 1.6235\n",
            "Epoch 13/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.3897 - loss: 1.6860 - val_accuracy: 0.4406 - val_loss: 1.6487\n",
            "Epoch 14/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.3942 - loss: 1.6706 - val_accuracy: 0.4553 - val_loss: 1.5918\n",
            "Epoch 15/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.4011 - loss: 1.6637 - val_accuracy: 0.4581 - val_loss: 1.5780\n",
            "Epoch 16/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.4072 - loss: 1.6459 - val_accuracy: 0.4431 - val_loss: 1.6177\n",
            "Epoch 17/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4040 - loss: 1.6454 - val_accuracy: 0.4460 - val_loss: 1.5987\n",
            "Epoch 18/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4045 - loss: 1.6460 - val_accuracy: 0.4547 - val_loss: 1.5839\n",
            "Epoch 19/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4095 - loss: 1.6279 - val_accuracy: 0.4430 - val_loss: 1.5933\n",
            "Epoch 20/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4088 - loss: 1.6284 - val_accuracy: 0.4482 - val_loss: 1.5766\n",
            "Epoch 21/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4137 - loss: 1.6232 - val_accuracy: 0.4555 - val_loss: 1.5919\n",
            "Epoch 22/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4164 - loss: 1.6137 - val_accuracy: 0.4538 - val_loss: 1.5885\n",
            "Epoch 23/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 42ms/step - accuracy: 0.4154 - loss: 1.6142 - val_accuracy: 0.4585 - val_loss: 1.5568\n",
            "Epoch 24/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4230 - loss: 1.5963 - val_accuracy: 0.4619 - val_loss: 1.5595\n",
            "Epoch 25/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4207 - loss: 1.6033 - val_accuracy: 0.4487 - val_loss: 1.5784\n",
            "Epoch 26/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4157 - loss: 1.6155 - val_accuracy: 0.4570 - val_loss: 1.5611\n",
            "Epoch 27/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4279 - loss: 1.5871 - val_accuracy: 0.4386 - val_loss: 1.5802\n",
            "Epoch 28/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4225 - loss: 1.5922 - val_accuracy: 0.4626 - val_loss: 1.5465\n",
            "Epoch 29/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4275 - loss: 1.5810 - val_accuracy: 0.4392 - val_loss: 1.5768\n",
            "Epoch 30/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4233 - loss: 1.5944 - val_accuracy: 0.4686 - val_loss: 1.5607\n",
            "Epoch 31/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4251 - loss: 1.5819 - val_accuracy: 0.4683 - val_loss: 1.5405\n",
            "Epoch 32/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4295 - loss: 1.5752 - val_accuracy: 0.4634 - val_loss: 1.5308\n",
            "Epoch 33/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.4307 - loss: 1.5744 - val_accuracy: 0.4522 - val_loss: 1.5484\n",
            "Epoch 34/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4325 - loss: 1.5758 - val_accuracy: 0.4546 - val_loss: 1.5675\n",
            "Epoch 35/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4274 - loss: 1.5713 - val_accuracy: 0.4619 - val_loss: 1.5376\n",
            "Epoch 36/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4307 - loss: 1.5680 - val_accuracy: 0.4591 - val_loss: 1.5318\n",
            "Epoch 37/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4347 - loss: 1.5644 - val_accuracy: 0.4527 - val_loss: 1.5550\n",
            "Epoch 38/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4337 - loss: 1.5670 - val_accuracy: 0.4578 - val_loss: 1.5435\n",
            "Epoch 39/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4408 - loss: 1.5492 - val_accuracy: 0.4674 - val_loss: 1.5438\n",
            "Epoch 40/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4339 - loss: 1.5572 - val_accuracy: 0.4607 - val_loss: 1.5686\n",
            "Epoch 41/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4392 - loss: 1.5573 - val_accuracy: 0.4678 - val_loss: 1.5228\n",
            "Epoch 42/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4426 - loss: 1.5495 - val_accuracy: 0.4611 - val_loss: 1.5384\n",
            "Epoch 43/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4381 - loss: 1.5546 - val_accuracy: 0.4599 - val_loss: 1.5402\n",
            "Epoch 44/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.4456 - loss: 1.5475 - val_accuracy: 0.4719 - val_loss: 1.5150\n",
            "Epoch 45/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.4431 - loss: 1.5483 - val_accuracy: 0.4642 - val_loss: 1.5406\n",
            "Epoch 46/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4410 - loss: 1.5466 - val_accuracy: 0.4626 - val_loss: 1.5516\n",
            "Epoch 47/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4398 - loss: 1.5505 - val_accuracy: 0.4686 - val_loss: 1.5251\n",
            "Epoch 48/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.4430 - loss: 1.5470 - val_accuracy: 0.4770 - val_loss: 1.5088\n",
            "Epoch 49/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4503 - loss: 1.5246 - val_accuracy: 0.4771 - val_loss: 1.5160\n",
            "Epoch 50/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4451 - loss: 1.5340 - val_accuracy: 0.4719 - val_loss: 1.5256\n",
            "Epoch 51/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.4446 - loss: 1.5401 - val_accuracy: 0.4486 - val_loss: 1.5601\n",
            "Epoch 52/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.4447 - loss: 1.5318 - val_accuracy: 0.4651 - val_loss: 1.5243\n",
            "Epoch 53/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.4515 - loss: 1.5288 - val_accuracy: 0.4729 - val_loss: 1.5056\n",
            "Epoch 54/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4492 - loss: 1.5273 - val_accuracy: 0.4639 - val_loss: 1.5190\n",
            "Epoch 55/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4424 - loss: 1.5397 - val_accuracy: 0.4612 - val_loss: 1.5356\n",
            "Epoch 56/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4498 - loss: 1.5251 - val_accuracy: 0.4730 - val_loss: 1.5032\n",
            "Epoch 57/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4544 - loss: 1.5203 - val_accuracy: 0.4781 - val_loss: 1.4988\n",
            "Epoch 58/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.4453 - loss: 1.5352 - val_accuracy: 0.4621 - val_loss: 1.5255\n",
            "Epoch 59/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4494 - loss: 1.5199 - val_accuracy: 0.4661 - val_loss: 1.5028\n",
            "Epoch 60/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4501 - loss: 1.5223 - val_accuracy: 0.4782 - val_loss: 1.5006\n",
            "Epoch 61/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4503 - loss: 1.5146 - val_accuracy: 0.4652 - val_loss: 1.5135\n",
            "Epoch 62/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.4513 - loss: 1.5186 - val_accuracy: 0.4718 - val_loss: 1.5230\n",
            "Epoch 63/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4549 - loss: 1.5101 - val_accuracy: 0.4785 - val_loss: 1.5042\n",
            "Epoch 64/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.4515 - loss: 1.5144 - val_accuracy: 0.4668 - val_loss: 1.5121\n",
            "Epoch 65/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.4548 - loss: 1.5134 - val_accuracy: 0.4750 - val_loss: 1.5123\n",
            "Epoch 66/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4546 - loss: 1.5174 - val_accuracy: 0.4744 - val_loss: 1.5107\n",
            "Epoch 67/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4566 - loss: 1.5136 - val_accuracy: 0.4764 - val_loss: 1.5042\n",
            "Epoch 68/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.4513 - loss: 1.5123 - val_accuracy: 0.4777 - val_loss: 1.4972\n",
            "Epoch 69/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.4531 - loss: 1.5068 - val_accuracy: 0.4799 - val_loss: 1.4957\n",
            "Epoch 70/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4602 - loss: 1.4963 - val_accuracy: 0.4840 - val_loss: 1.4822\n",
            "Epoch 71/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4603 - loss: 1.5114 - val_accuracy: 0.4737 - val_loss: 1.4972\n",
            "Epoch 72/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4508 - loss: 1.5078 - val_accuracy: 0.4791 - val_loss: 1.5146\n",
            "Epoch 73/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.4561 - loss: 1.5081 - val_accuracy: 0.4644 - val_loss: 1.5348\n",
            "Epoch 74/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4551 - loss: 1.5068 - val_accuracy: 0.4638 - val_loss: 1.5104\n",
            "Epoch 75/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4581 - loss: 1.5041 - val_accuracy: 0.4545 - val_loss: 1.5436\n",
            "Epoch 76/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4539 - loss: 1.5029 - val_accuracy: 0.4695 - val_loss: 1.5015\n",
            "Epoch 77/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4602 - loss: 1.4979 - val_accuracy: 0.4817 - val_loss: 1.4898\n",
            "Epoch 78/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4594 - loss: 1.4978 - val_accuracy: 0.4817 - val_loss: 1.4866\n",
            "Epoch 79/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4625 - loss: 1.4926 - val_accuracy: 0.4717 - val_loss: 1.5131\n",
            "Epoch 80/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4589 - loss: 1.4998 - val_accuracy: 0.4613 - val_loss: 1.5222\n",
            "Epoch 81/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.4590 - loss: 1.5021 - val_accuracy: 0.4863 - val_loss: 1.5070\n",
            "Epoch 82/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.4639 - loss: 1.4910 - val_accuracy: 0.4801 - val_loss: 1.4777\n",
            "Epoch 83/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4604 - loss: 1.4874 - val_accuracy: 0.4821 - val_loss: 1.4881\n",
            "Epoch 84/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4611 - loss: 1.4928 - val_accuracy: 0.4697 - val_loss: 1.5068\n",
            "Epoch 85/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4572 - loss: 1.5003 - val_accuracy: 0.4806 - val_loss: 1.4876\n",
            "Epoch 86/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4652 - loss: 1.5003 - val_accuracy: 0.4786 - val_loss: 1.4767\n",
            "Epoch 87/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4641 - loss: 1.4821 - val_accuracy: 0.4830 - val_loss: 1.4939\n",
            "Epoch 88/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4636 - loss: 1.4801 - val_accuracy: 0.4865 - val_loss: 1.4773\n",
            "Epoch 89/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4640 - loss: 1.4866 - val_accuracy: 0.4838 - val_loss: 1.4829\n",
            "Epoch 90/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.4662 - loss: 1.4850 - val_accuracy: 0.4683 - val_loss: 1.5074\n",
            "Epoch 91/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4656 - loss: 1.4844 - val_accuracy: 0.4724 - val_loss: 1.4986\n",
            "Epoch 92/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4615 - loss: 1.4816 - val_accuracy: 0.4717 - val_loss: 1.5027\n",
            "Epoch 93/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4692 - loss: 1.4758 - val_accuracy: 0.4897 - val_loss: 1.4906\n",
            "Epoch 94/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4653 - loss: 1.4853 - val_accuracy: 0.4852 - val_loss: 1.4768\n",
            "Epoch 95/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - accuracy: 0.4663 - loss: 1.4755 - val_accuracy: 0.4718 - val_loss: 1.5085\n",
            "Epoch 96/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.4712 - loss: 1.4764 - val_accuracy: 0.4803 - val_loss: 1.4870\n",
            "Epoch 97/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.4644 - loss: 1.4918 - val_accuracy: 0.4709 - val_loss: 1.4980\n",
            "Epoch 98/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - accuracy: 0.4655 - loss: 1.4844 - val_accuracy: 0.4679 - val_loss: 1.5049\n",
            "Epoch 99/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4693 - loss: 1.4784 - val_accuracy: 0.4703 - val_loss: 1.5218\n",
            "Epoch 100/100\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.4635 - loss: 1.4818 - val_accuracy: 0.4821 - val_loss: 1.4845\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4865 - loss: 1.4778\n",
            " Độ chính xác trên tập test: 0.4821000099182129\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            " Ảnh được dự đoán là: cat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/frog.jpg'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-dInDy4e-TCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/ngựa.webp'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yLomFI2C-Vv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/ngựa.webp'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TD6oLxdQA4IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/plane.jpg'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_Iscm-W7A8df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/ship.jpg'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F--GECZQA9DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\" Độ chính xác trên tập test:\", test_acc)\n",
        "\n",
        "img_path = '/content/drive/MyDrive/cifar/truck.avif'\n",
        "\n",
        "img = load_img(img_path, target_size=(32, 32))\n",
        "img = img_to_array(img)\n",
        "img = img.astype('float32') / 255.0\n",
        "img = img.reshape(1, 32 * 32 * 3)\n",
        "\n",
        "prediction = model.predict(img)\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\" Ảnh được dự đoán là:\", label_names[predicted_label])\n",
        "\n",
        "plt.imshow(img.reshape(32, 32, 3))\n",
        "plt.title(f\"Dự đoán: {label_names[predicted_label]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Hfn3KkcCA-73"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1U8RsxNWuJ4yfv5-VtEcn99_QhbKoNLh5",
      "authorship_tag": "ABX9TyPwfXU7zHO1O8nulnDiz0ei",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}